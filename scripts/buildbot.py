"""
Builds sumatra and uploads results to s3 for easy analysis, viewable at:
http://kjkpub.s3.amazonaws.com/sumatrapdf/buildbot/index.html
"""
import os, os.path, shutil, sys, time, re, string, datetime

from util import log, run_cmd_throw, run_cmd, test_for_flag, s3UploadFilePublic
from util import s3UploadDataPublic, ensure_s3_doesnt_exist, ensure_path_exists
from util import parse_svninfo_out, s3List, s3Delete, verify_started_in_right_directory

def file_size(p):
  return os.path.getsize(p)

def skip_error(s):
	if "C2220" in s: return True # warning treated as error
	return False

# given a text generated by compiler, extract the lines that contain
# error information
def extract_compile_errors(s):
	errors = []
	for l in s.split('\n'):
		if ": error " in l or ": warning " in l:
			if not skip_error(l) and l not in errors:
				errors.append(l)
	return errors

g_src_trans_map = None
def rebuild_trans_src_path_cache():
	global g_src_trans_map
	g_src_trans_map = {}
	for root, dirs, files in os.walk("src"):
		for file in files:
			file_path = os.path.join(root, file)
			g_src_trans_map[file_path.lower()] = file_path

# for some reason file names are lower-cased and the url has exact case
# we need to convert src_path to have the exact case for urls to work
# i.e. given "src\doc.h" we need to return "src\Doc.h"
def trans_src_path(s):
	if s not in g_src_trans_map:
		print("%s not in g_src_trans_map" % s)
		print(g_src_trans_map.keys())
	return g_src_trans_map[s]

def a(url, txt): return '<a href="' + url + '">' + txt + '</a>'

# Turn:
# src\utils\allocator.h(156)
# Into:
# <a href="https://code.google.com/p/sumatrapdf/source/browse/trunk/src/utils/allocator.h#156">src\utils\allocator.h(156)</a>
def htmlize_src_link(s):
	parts = s.split("(")
	src_path = parts[0] # src\utils\allocator.h
	src_path = trans_src_path(src_path) # src\utils\Allocator.h
	src_path_in_url = src_path.replace("\\", "/")
	src_line = parts[1][:-1] # "156)"" => "156"
	url = "https://code.google.com/p/sumatrapdf/source/browse/trunk/" + src_path_in_url + "#" + src_line
	return a(url, src_path + "(" + src_line + ")")

# Turn:
# c:\users\kkowalczyk\src\sumatrapdf\src\utils\allocator.h(156) : warning C6011: Dereferencing NULL pointer 'node'. : Lines: 149, 150, 151, 153, 154, 156
# Into:
# <a href="https://code.google.com/p/sumatrapdf/source/browse/trunk/src/utils/allocator.h#156">src\utils\allocator.h(156)</a>:<br>
# warning C6011: Dereferencing NULL pointer 'node'. : Lines: 149, 150, 151, 153, 154, 156
def htmlize_error_lines(lines):
	if len(lines) == 0: return []
	res = []
	# TODO: would be nicer if "sumatrapdf_buildbot" wasn't hard-coded, but don't know
	# how to get this reliably
	rel_path_start = lines[0].find("sumatrapdf_buildbot\\") + len("sumatrapdf_buildbot\\")
	for l in lines:
		l = l[rel_path_start:]
		err_start = l.find(" : ")
		src = l[:err_start]
		msg = l[err_start + 3:]
		a = htmlize_src_link(src)
		s = a + " " + msg
		res.append(s)
	return res

def pre(s): return '<pre style="white-space: pre-wrap;">' + s + '</pre>'

def gen_errors_html(errors, ver):
	s = "<html><body>"
	s += "There were %d warnings and errors in Sumatra build %s" % (len(errors), str(ver))
	s += pre(string.join(errors, ""))
	s += "</pre>"
	s += "</body></html>"
	return s

def str2bool(s): 
	if s.lower() in ("true", "1"): return True
	if s.lower() in ("false", "0"): return False
	assert(False)

def test_ser():
	stats = Stats()
	print stats.to_s()

class Stats(object):
	int_fields = ("analyze_warnings_count", "release_sumatrapdf_exe_size", "release_sumatrapdf_no_mupdf_exe_size",
		"release_installer_exe_size", "release_libmupdf_dll_size", "release_nppdfviewer_dll_size",
		"release_pdffilter_dll_size", "release_pdfpreview_dll_size")
	bool_fields = ("release_failed")
	def __init__(self):
		# serialized to stats.txt
		self.analyze_warnings_count = 0
		self.release_failed = False
		self.release_sumatrapdf_exe_size = 0
		self.release_sumatrapdf_no_mupdf_exe_size = 0
		self.release_installer_exe_size = 0
		self.release_libmupdf_dll_size = 0
		self.release_nppdfviewer_dll_size = 0
		self.release_pdffilter_dll_size = 0
		self.release_pdfpreview_dll_size = 0

		# just for passing data aroun
		self.analyze_out = None
		self.release_build_log = None

	def add_field(self, name):
		val = self.__getattribute__ (name)
		self.fields.append("%s: %s" % (name, str(val)))

	def to_s(self):
		self.fields = []
		self.add_field("analyze_warnings_count")
		self.add_field("release_failed")
		if not self.release_failed:
			for f in ("release_sumatrapdf_exe_size", "release_sumatrapdf_no_mupdf_exe_size",
		"release_installer_exe_size", "release_libmupdf_dll_size", "release_nppdfviewer_dll_size",
		"release_pdffilter_dll_size", "release_pdfpreview_dll_size"):
				self.add_field(f)
		return string.join(self.fields, "\n")

	def set_field(self, name, val, tp):
		if tp in ("str", "string"):
			self.__setattr__(name, val)
			return
		if tp == "bool":
			self.__setattr__(name, str2bool(val))
			return
		if tp in ("int", "num"):
			self.__setattr__(name, int(val))
			return
		assert(False)

	def from_s(self):
		lines = s.split("\n")
		for l in lines:
			(name, val) = l.split(": ", 1)
			if name in int_fields: self.set_field(name, val, "int")
			elif name in bool_fields: self.set_field(name, val, "bool")
			else: assert(False)

def get_cache_dir():
	cache_dir = os.path.join("..", "sumatrapdfcache", "buildbot")
	if not os.path.exists(cache_dir): os.makedirs(cache_dir)
	return cache_dir

def s3UploadDataPublicWithContentType(data, s3_path):
	# writing to a file to force boto to set Content-Type based on file extension.
	# TODO: there must be a simpler way
	tmp_name = os.path.basename(s3_path)
	tmp_path = os.path.join(get_cache_dir(), tmp_name)
	open(tmp_path, "w").write(data)
	s3UploadFilePublic(tmp_path, s3_path)
	os.remove(tmp_path)

# return true if we already have results for a given build number in s3
def has_already_been_built(ver):
	s3_dir = "sumatrapdf/buildbot/"
	expected_name = s3_dir + ver + "/analyze.html"
	keys = s3List(s3_dir)
	for k in keys:
		if k.name == expected_name: return True
	return False

# given a list of files from s3 in the form ${ver}/${name}, group them
# into a list of lists, [[${ver}, [${name1}, ${name2}]], ${ver2}, [${name1}]] etc.
# we rely that the files are already sorted by ${ver}
def group_by_ver(files):
	res = []
	curr_ver = None
	curr_ver_names = []
	for f in files:
		(ver, name) = f.split("/", 1)
		if ver == curr_ver:
			curr_ver_names  
		else:
			if curr_ver != None:
				assert(len(curr_ver_names) > 0)
				res.append([curr_ver, curr_ver_names])
			curr_ver = ver
			curr_ver_names = [name]
	if curr_ver != None:
		assert(len(curr_ver_names) > 0)
		res.append([curr_ver, curr_ver_names])
	return res	

# build sumatrapdf/buildbot/index.html summary page that links to each 
# sumatrapdf/buildbot/${ver}/analyze.html
# TODO: download stats.txt files locally
# TODO: add summary stats from stats.txt
def build_index_html():
	s3_dir = "sumatrapdf/buildbot/"
	html = "<html><body>\n"
	html += "<p>SumatraPDF buildbot results:</p>\n"
	html += "<ul>\n"
	names = [k.name[len(s3_dir):] for k in s3List(s3_dir) if k.name.endswith("/analyze.html")]
	names.sort(reverse=True, key=lambda name: int(name.split("/")[0]))
	#print(names)
	# TODO: this should be a table
	# TODO: fail/ok for release build, link to build log if failed
	# TODO: number of analyze warning
	files_by_ver = group_by_ver(names)
	for arr in files_by_ver:
		(ver, files) = arr
		assert("analyze.html" in files)
		url = "http://kjkpub.s3.amazonaws.com/" + s3_dir + "analyze.html"
		html += "  <li>Build " + a(url, ver) + "</li>\n"
	html += "</ul>\n"
	html += "</body></html>\n"
	#print(html)
	s3UploadDataPublicWithContentType(html, "sumatrapdf/buildbot/index.html")

def build_release(stats, ver):
	config = "CFG=rel"
	obj_dir = "obj-rel"
	extcflags = "EXTCFLAGS=-DSVN_PRE_RELEASE_VER=%s" % ver
	platform = "PLATFORM=X86"

	shutil.rmtree(obj_dir, ignore_errors=True)
	shutil.rmtree(os.path.join("mupdf", "generated"), ignore_errors=True)
	(out, err, errcode) = run_cmd("nmake", "-f", "makefile.msvc", config, extcflags, platform, "all_sumatrapdf")
	stats.release_build_log = None
	stats.release_failed = False
	if errcode != 0:
		stats.release_build_log = out
		stats.release_failed = True
		return
	stats.release_sumatrapdf_exe_size = file_size(os.path.join(obj_dir), "SumatraPDF.exe")
	stats.release_sumatrapdf_no_mupdf_exe_size = file_size(os.path.join(obj_dir), "SumatraPDF-no-MuPDF.exe")
	stats.release_installer_exe_size = file_size(os.path.join(obj_dir), "Installer.exe")
	stats.release_libmupdf_dll_size = file_size(os.path.join(obj_dir), "libmupdf.dll")
	stats.release_nppdfviewer_dll_size = file_size(os.path.join(obj_dir), "npPdfViewer.dll")
	stats.release_pdffilter_dll_size = file_size(os.path.join(obj_dir), "PdfFilter.dll")
	stats.release_pdfpreview_dll_size = file_size(os.path.join(obj_dir), "PdfPreview.dll")

def build_analyze(stats, ver):
	config = "CFG=rel"
	obj_dir = "obj-rel"
	extcflags = "EXTCFLAGS=-DSVN_PRE_RELEASE_VER=%s" % ver
	platform = "PLATFORM=X86"

	shutil.rmtree(obj_dir, ignore_errors=True)
	shutil.rmtree(os.path.join("mupdf", "generated"), ignore_errors=True)
	# disable ucrt because vs2012 doesn't support it and I give it priority
	# over 2010 (if both installed) hoping it has better /analyze
	(out, err, errcode) = run_cmd("nmake", "-f", "makefile.msvc", "WITH_SUM_ANALYZE=yes", "WITH_UCRT=no", config, extcflags, platform, "all_sumatrapdf")
	stats.analyze_out = out

# returns local and latest (on the server) svn versions
def get_svn_versions():
	(out, err) = run_cmd_throw("svn", "info")
	ver_local = str(parse_svninfo_out(out))
	(out, err) = run_cmd_throw("svn", "info", "https://sumatrapdf.googlecode.com/svn/trunk")
	ver_latest = str(parse_svninfo_out(out))
	return ver_local, ver_latest

def svn_update_to_ver(ver):
	run_cmd_throw("svn", "update", "-r" + ver)
	rebuild_trans_src_path_cache()

# TODO: maybe add debug build and 64bit release?
def build_version(ver):
	print("Building version %s" % ver)
	svn_update_to_ver(ver)

	stats = Stats()

	start_time = datetime.datetime.now()
	build_analyze(stats, ver)
	dur = datetime.datetime.now() - start_time
	print("%s for analyze build" % str(dur))

	start_time = datetime.datetime.now()
	build_release(stats, ver)
	dur = datetime.datetime.now() - start_time
	print("%s for release build" % str(dur))

	errors = htmlize_error_lines(extract_compile_errors(stats.analyze_out))
	html = gen_errors_html(errors, ver)
	stats.analyze_warnings_count = len(errors)
	stats_txt = stats.to_s()

	s3dir = "sumatrapdf/buildbot/%s/" % ver

	s3UploadDataPublicWithContentType(html, s3dir + "analyze.html")
	s3UploadDataPublicWithContentType(stats_txt, s3dir + "stats.txt")

	if stats.release_failed:
		s3UploadDataPublicWithContentType(stats.release_build_log, s3dir + "release_build_log.txt")

	build_index_html()

# for testing
def build_curr():
	(local_ver, latest_ver) = get_svn_versions()
	print("local ver: %s, latest ver: %s" % (local_ver, latest_ver))
	if not has_already_been_built(local_ver):
		build_version(local_ver)
	else:
		print("We have already built revision %s" % local_ver)

def buildbot_loop():
	while True:
		(local_ver, latest_ver) = get_svn_versions()
		print("local ver: %s, latest ver: %s" % (local_ver, latest_ver))
		while int(local_ver) < int(latest_ver):
			if not has_already_been_built(local_ver):
				build_version(local_ver)
			else:
				print("We have already built revision %s" % local_ver)
			local_ver = str(int(local_ver)+1)
		print("Sleeping for 15 minutes")
		time.sleep(60*15) # 15 mins

def main():
	verify_started_in_right_directory()
	# to avoid problems, we build a separate source tree, just for the buildbot
	src_path = os.path.join("..", "sumatrapdf_buildbot")
	ensure_path_exists(src_path)
	os.chdir(src_path)

	#build_index_html()
	#build_curr()
	buildbot_loop()

if __name__ == "__main__":
	main()
